# ğŸ§ Deepfake Audio Authenticity Detection System

A **production-ready ML system** to detect whether an uploaded audio file is **Real Human Speech** or **AI-Generated / Deepfake Audio**.

This project is not a demo script â€” it is a **fully deployed, containerized, endâ€‘toâ€‘end system** covering:

* Audio preprocessing & feature extraction
* ML model training & version compatibility
* FastAPI backend
* Frontend integration
* Dockerized deployment on Render

ğŸ”— **Live Demo**: [https://deepfake-audio-authenticity-detection.onrender.com](https://deepfake-audio-authenticity-detection.onrender.com)

---

## ğŸš€ Key Highlights

* ğŸ” **ML-based Deepfake Detection** using audio signal features
* ğŸ§  Model retrained with strict **production version parity** (no sklearn mismatch)
* âš™ï¸ **FastAPI backend** with file upload support
* ğŸ¨ Simple frontend UI for real-time testing
* ğŸ³ **Dockerized** for consistent builds
* â˜ï¸ **Deployed on Render** (publicly accessible)

This project intentionally focuses on **engineering correctness**, not just model accuracy.

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser    â”‚
â”‚ (Frontend)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚  Audio Upload (POST)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI Application    â”‚
â”‚  (api/app.py)            â”‚
â”‚                          â”‚
â”‚  - /predict endpoint     â”‚
â”‚  - UploadFile handling   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Audio Preprocessing      â”‚
â”‚ (ml/preprocess.py)       â”‚
â”‚                          â”‚
â”‚ - Resampling             â”‚
â”‚ - Mono conversion        â”‚
â”‚ - Silence handling       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature Extraction       â”‚
â”‚ (ml/features.py)         â”‚
â”‚                          â”‚
â”‚ - Spectral features      â”‚
â”‚ - MFCC-based stats       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ML Inference              â”‚
â”‚ (Random Forest Model)    â”‚
â”‚ models/rf_model.pkl      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prediction Response      â”‚
â”‚ { Real / AI-generated }  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Machine Learning Pipeline

### 1. Data Handling

* Audio files loaded using `librosa`
* Converted to a consistent sample rate
* Normalized and validated

### 2. Feature Extraction

Extracted features include:

* Spectral centroid
* Spectral bandwidth
* Zero-crossing rate
* MFCC statistical aggregates

These features are designed to capture **artifacts common in synthetic audio**.

### 3. Models Trained

* **Scaled Logistic Regression** (baseline)
* **Random Forest Classifier** (final model)

### 4. Final Model

* **Random Forest** selected due to superior validation performance
* Serialized as `rf_model.pkl`
* Retrained under **scikit-learn 1.4.2** to match production runtime

---

## ğŸ§ª Validation Results (Final Training)

```
Accuracy: 98%

Class 0 (Real Audio):
Precision: 0.99 | Recall: 0.98

Class 1 (AI-generated Audio):
Precision: 0.98 | Recall: 0.99
```

âš ï¸ Note: Metrics are secondary here â€” **deployment correctness and compatibility** were the main goals.

---

## ğŸ› ï¸ Tech Stack

**Backend**

* Python 3.10
* FastAPI
* Uvicorn

**ML / Audio**

* scikit-learn 1.4.2
* numpy 1.26.4
* scipy 1.11.4
* librosa
* soundfile

**Frontend**

* HTML
* CSS
* JavaScript (Fetch API)

**DevOps / Deployment**

* Docker
* Render

---

## ğŸ“¦ Project Structure

```
Deepfake-audio/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py           # FastAPI app
â”‚   â”œâ”€â”€ inference.py     # Model loading & prediction
â”‚   â””â”€â”€ schemas.py
â”‚
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ train.py         # Model training script
â”‚   â”œâ”€â”€ preprocess.py   # Audio preprocessing
â”‚   â””â”€â”€ features.py     # Feature extraction
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ rf_model.pkl     # Trained ML model
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ³ Docker & Deployment

The application is fully containerized.

Key deployment considerations:

* Exact dependency pinning
* Python version parity (3.10)
* Model retraining to avoid sklearn incompatibility warnings

Deployment is handled automatically by **Render** on push to `main`.

---

## âš ï¸ Known Limitations & Future Improvements

* Large model file (~62 MB) â€” should be moved to object storage or Git LFS
* No authentication (public demo)
* Synchronous inference (can be async/queued)
* Dataset not included in repo

---

## ğŸ“Œ Why This Project Matters

This project demonstrates:

* Real-world ML deployment challenges
* Version mismatch debugging
* End-to-end ownership (data â†’ model â†’ API â†’ UI â†’ cloud)

It reflects **engineering maturity**, not just ML theory.

---

## ğŸ‘¤ Author

**Rupal**
B.Tech CSE Student

---

## ğŸ“„ License

This project is for educational and demonstration purposes.
